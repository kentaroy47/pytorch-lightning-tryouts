{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use CIFAR 10 to train CNNs with Pytorch-lightning!\n",
    "let's develop 16FP and multi-GPU training.. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.models.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from models import *\n",
    "# from utils import progress_bar\n",
    "\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "170500096it [00:38, 7393375.33it/s]                               \u001b[A"
     ]
    }
   ],
   "source": [
    "# define lightning model\n",
    "class LightningModel(LightningModule):\n",
    "    \"\"\"\n",
    "    Sample model to show how to define a template\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        # init superclass\n",
    "        super(LightningModel, self).__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.batch_size = hparams.batch_size\n",
    "\n",
    "        # if you specify an example input, the summary will show input/output for each layer\n",
    "        self.example_input_array = torch.rand(5, 28 * 28)\n",
    "\n",
    "        # build model\n",
    "        self.__build_model()\n",
    "\n",
    "    # ---------------------\n",
    "    # MODEL SETUP\n",
    "    # ---------------------\n",
    "    def __build_model(self):\n",
    "        \"\"\"\n",
    "        Layout model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # inlayer\n",
    "        self.c_d1 = nn.Linear(in_features=self.hparams.in_features,\n",
    "                              out_features=self.hparams.hidden_dim)\n",
    "        self.c_d1_bn = nn.BatchNorm1d(self.hparams.hidden_dim)\n",
    "        self.c_d1_drop = nn.Dropout(self.hparams.drop_prob)\n",
    "        # midlayer\n",
    "        #self.c_dm = nn.Linear(in_features=self.hparams.hidden_dim,\n",
    "        #                      out_features=self.hparams.hidden_dim)\n",
    "        #self.c_dm_bn = nn.BatchNorm1d(self.hparams.hidden_dim)\n",
    "        #self.c_dm_drop = nn.Dropout(self.hparams.drop_prob)\n",
    "        # outlayer\n",
    "        self.c_d2 = nn.Linear(in_features=self.hparams.hidden_dim,\n",
    "                              out_features=self.hparams.out_features)\n",
    "\n",
    "    # ---------------------\n",
    "    # TRAINING\n",
    "    # ---------------------\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        No special modification required for lightning, define as you normally would\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.c_d1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.c_d1_bn(x)\n",
    "        x = self.c_d1_drop(x)\n",
    "        \n",
    "#        x = self.c_dm(x)\n",
    "#        x = torch.relu(x)\n",
    "#        x = self.c_dm_bn(x)\n",
    "#        x = self.c_dm_drop(x)\n",
    "        \n",
    "        x = self.c_d2(x)\n",
    "        logits = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    # criterion的にロスを定義する？\n",
    "    def loss(self, labels, logits):\n",
    "        nll = F.nll_loss(logits, labels)\n",
    "        return nll\n",
    "    \n",
    "    # 学習のstepで何をやるか定義\n",
    "    def training_step(self, data_batch, batch_i):\n",
    "        \"\"\"\n",
    "        Lightning calls this inside the training loop\n",
    "        :param data_batch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # forward pass\n",
    "        x, y = data_batch\n",
    "        x = x.view(x.size(0), -1) #全結合のためflatten\n",
    "\n",
    "        y_hat = self.forward(x) # forward\n",
    "\n",
    "        # calculate loss\n",
    "        loss_val = self.loss(y, y_hat)\n",
    "\n",
    "        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning\n",
    "        if self.trainer.use_dp:\n",
    "            loss_val = loss_val.unsqueeze(0)\n",
    "\n",
    "        output = OrderedDict({\n",
    "            'loss': loss_val\n",
    "        })\n",
    "\n",
    "        # can also return just a scalar instead of a dict (return loss_val)\n",
    "        return output\n",
    "\n",
    "    # valで何をやるか定義する\n",
    "    def validation_step(self, data_batch, batch_i):\n",
    "        \"\"\"\n",
    "        Lightning calls this inside the validation loop\n",
    "        :param data_batch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x, y = data_batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss_val = self.loss(y, y_hat)\n",
    "\n",
    "        # acc\n",
    "        labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n",
    "        val_acc = torch.tensor(val_acc)\n",
    "\n",
    "        if self.on_gpu:\n",
    "            val_acc = val_acc.cuda(loss_val.device.index)\n",
    "\n",
    "        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning\n",
    "        if self.trainer.use_dp:\n",
    "            loss_val = loss_val.unsqueeze(0)\n",
    "            val_acc = val_acc.unsqueeze(0)\n",
    "\n",
    "        output = OrderedDict({\n",
    "            'val_loss': loss_val,\n",
    "            'val_acc': val_acc,\n",
    "        })\n",
    "\n",
    "        # can also return just a scalar instead of a dict (return loss_val)\n",
    "        return output\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Called at the end of validation to aggregate outputs\n",
    "        :param outputs: list of individual outputs of each validation step\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # if returned a scalar from validation_step, outputs is a list of tensor scalars\n",
    "        # we return just the average in this case (if we want)\n",
    "        # return torch.stack(outputs).mean()\n",
    "\n",
    "        val_loss_mean = 0\n",
    "        val_acc_mean = 0\n",
    "        for output in outputs:\n",
    "            val_loss = output['val_loss']\n",
    "\n",
    "            # reduce manually when using dp\n",
    "            if self.trainer.use_dp:\n",
    "                val_loss = torch.mean(val_loss)\n",
    "            val_loss_mean += val_loss\n",
    "\n",
    "            # reduce manually when using dp\n",
    "            val_acc = output['val_acc']\n",
    "            if self.trainer.use_dp:\n",
    "                val_acc = torch.mean(val_acc)\n",
    "\n",
    "            val_acc_mean += val_acc\n",
    "\n",
    "        val_loss_mean /= len(outputs)\n",
    "        val_acc_mean /= len(outputs)\n",
    "        tqdm_dic = {'val_loss': val_loss_mean, 'val_acc': val_acc_mean}\n",
    "        return tqdm_dic\n",
    "\n",
    "    # ---------------------\n",
    "    # TRAINING SETUP\n",
    "    # ---------------------\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        return whatever optimizers we want here\n",
    "        :return: list of optimizers\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    # ここでデータローダーを定義する！\n",
    "    def __dataloader(self, train):\n",
    "        # init data generators\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (1.0,))])\n",
    "        dataset = MNIST(root=self.hparams.data_root, train=train,\n",
    "                        transform=transform, download=True)\n",
    "\n",
    "        # when using multi-node (ddp) we need to add the datasampler\n",
    "        train_sampler = None\n",
    "        batch_size = self.hparams.batch_size\n",
    "\n",
    "        if self.trainer.use_ddp:\n",
    "            train_sampler = DistributedSampler(dataset, rank=self.trainer.proc_rank)\n",
    "            batch_size = batch_size // self.trainer.world_size  # scale batch size\n",
    "\n",
    "        should_shuffle = train_sampler is None\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=should_shuffle,\n",
    "            sampler=train_sampler\n",
    "        )\n",
    "\n",
    "        return loader\n",
    "\n",
    "    @pl.data_loader\n",
    "    def tng_dataloader(self):\n",
    "        print('tng data loader called')\n",
    "        return self.__dataloader(train=True)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        print('val data loader called')\n",
    "        return self.__dataloader(train=False)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        print('test data loader called')\n",
    "        return self.__dataloader(train=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser, root_dir):  # pragma: no cover\n",
    "        \"\"\"\n",
    "        Parameters you define here will be available to your model through self.hparams\n",
    "        :param parent_parser:\n",
    "        :param root_dir:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        parser = HyperOptArgumentParser(strategy=parent_parser.strategy, parents=[parent_parser])\n",
    "\n",
    "        # param overwrites\n",
    "        # parser.set_defaults(gradient_clip=5.0)\n",
    "\n",
    "        # network params\n",
    "        parser.add_argument('--in_features', default=28 * 28, type=int)\n",
    "        parser.add_argument('--out_features', default=10, type=int)\n",
    "        # use 500 for CPU, 50000 for GPU to see speed difference\n",
    "        parser.add_argument('--hidden_dim', default=50000, type=int)\n",
    "        parser.opt_list('--drop_prob', default=0.2, options=[0.2, 0.5], type=float, tunable=False)\n",
    "\n",
    "        # data\n",
    "        parser.add_argument('--data_root', default=os.path.join(root_dir, 'mnist'), type=str)\n",
    "\n",
    "        # training params (opt)\n",
    "        parser.opt_list('--learning_rate', default=0.001 * 8, type=float,\n",
    "                        options=[0.0001, 0.0005, 0.001, 0.005],\n",
    "                        tunable=False)\n",
    "        parser.opt_list('--optimizer_name', default='adam', type=str,\n",
    "                        options=['adam'], tunable=False)\n",
    "\n",
    "        # if using 2 nodes with 4 gpus each the batch size here\n",
    "        #  (256) will be 256 / (2*8) = 16 per gpu\n",
    "        parser.opt_list('--batch_size', default=256 * 8, type=int,\n",
    "                        options=[32, 64, 128, 256], tunable=False,\n",
    "                        help='batch size will be divided over all gpus being used across all nodes')\n",
    "        return parser# Setup Dataset\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Lightning Modules\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from test_tube import HyperOptArgumentParser\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.root_module.root_module import LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import vgg16\n",
    "nn = vgg16()\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
